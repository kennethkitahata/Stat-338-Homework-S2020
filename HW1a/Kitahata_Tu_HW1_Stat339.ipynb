{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spencer Tu & Kenneth Kitahata\n",
    "#02/19/2020\n",
    "#HW1: Classification and Regression \n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_s1 = np.loadtxt(fname = \"http://colindawson.net/data/S1train.csv\", delimiter = (\",\"))\n",
    "test_s1 = np.loadtxt(fname = \"http://colindawson.net/data/S1test.csv\", delimiter = (\",\"))\n",
    "training_s2 = np.loadtxt(fname = \"http://colindawson.net/data/S2train.csv\", delimiter = (\",\"))\n",
    "test_s2 = np.loadtxt(fname = \"http://colindawson.net/data/S2test.csv\", delimiter = (\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a(i)\n",
    "#a and b are an array of numbers representing 2 vectors\n",
    "#calculates the euclidean disance between them\n",
    "def euclidean(vector1, vector2):\n",
    "    distance = np.sqrt(np.dot(vector1, vector1) - 2 * np.dot(vector1, vector2) + np.dot(vector2, vector2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a(ii)\n",
    "#a is the case array (your target)\n",
    "#b is an N x 2 matrix (your training set)\n",
    "#calculate distance between xnew and each point in training data, return array of distances\n",
    "def distance(point, training):\n",
    "    newtrain = training[:,1:3]\n",
    "    dist_array = np.zeros([len(training)])\n",
    "    for i in range(0, len(training)):\n",
    "        dist_array[i] = (euclidean(point, newtrain[i]))\n",
    "    return dist_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1a(iii)\n",
    "# return the indicies of K closest neighbors\n",
    "def closestneighbors(distance, K):\n",
    "    return np.argsort(distance)[:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a(iv)\n",
    "#this function returns the \"majority class\" of k closest neighbors\n",
    "# returns either 1, -1 or -100 in case of ties\n",
    "def majority(training, miniindex):\n",
    "    counter = np.zeros(2)\n",
    "    for i in range (len(miniindex)):\n",
    "        if training[miniindex[i], 0] == 1:\n",
    "            counter[0] += 1\n",
    "        else:\n",
    "            counter[1] += 1\n",
    "    if counter[0] > counter[1]:\n",
    "        return 1\n",
    "    elif counter[1] > counter [0]:\n",
    "        return -1\n",
    "    else:\n",
    "        return -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1a(v)\n",
    "# Assuming xnew is a set of instances and it is in Nx2 matrix\n",
    "# Assuming training is a training set and it is in Nx3 matrix\n",
    "# return a vector of class predictions (1 or -1) for xnew\n",
    "\n",
    "#how to deal with ties\n",
    "def KNN(xnew, train, k):\n",
    "    labels = np.zeros([len(xnew)])\n",
    "    for i in range(0, len(xnew)):\n",
    "        dist = distance(xnew[i, 1:], train)\n",
    "        neighbors = closestneighbors(dist, k)\n",
    "        label = majority(train, neighbors)\n",
    "        \n",
    "        #if tie, run again with k - 1 neighbors\n",
    "        while label == -100:\n",
    "            neighbors = closestneighbors(dist, k - 1)\n",
    "            label = majority(train, neighbors) \n",
    "            \n",
    "        labels[i] = majority(train, neighbors)    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1b(i)\n",
    "def error(label, true):\n",
    "    num = 0\n",
    "    denom = len(label)\n",
    "    for i in range(0, len(label)):\n",
    "        if label[i] == true[i]:\n",
    "            num += 1\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b(ii)\n",
    "def performance(name, traindata, xnew, labels, metric, k):\n",
    "    if name == \"KNN\":\n",
    "        predictions = KNN(xnew, traindata, k)\n",
    "        if metric == \"accuracy\":\n",
    "            score = error(predictions, labels)\n",
    "            return score\n",
    "    else:\n",
    "        print('In Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b(iii)\n",
    "#return an array of performance scores for each fold\n",
    "# if \"YES\" to generalization, return an array of array of performane scores, array of generalization error, and \n",
    "#lastly an array of training error\n",
    "\n",
    "def CV(data, folds, k, name, metric, generalization): \n",
    "    np.random.shuffle(data)\n",
    "    datainfolds = np.array_split(data, folds)\n",
    "    generalization_error = np.array([])\n",
    "    \n",
    "    #array with performance of classifier for each fold\n",
    "    classifier_performance = np.array([])\n",
    "    length = list(range(folds))\n",
    "    #iterate through each fold \n",
    "    for i in length:\n",
    "        train = np.empty_like(datainfolds[0])\n",
    "        index = length.copy()\n",
    "        del index[i]\n",
    "        for j in index:      \n",
    "            train = np.append(train, datainfolds[j], axis = 0)\n",
    "        cut = len(datainfolds[0])\n",
    "        train = np.delete(train, slice(0, cut), axis = 0)\n",
    "        validate = datainfolds[i]\n",
    "        label = validate[:, 0]\n",
    "        print(train)\n",
    "        print(validate)\n",
    "        print(label)\n",
    "        score = performance(name, train, validate, label, metric, k)\n",
    "        classifier_performance = np.append(classifier_performance, score)\n",
    "    \n",
    "        if generalization == \"Yes\":\n",
    "            g_labels = train[:, 0]\n",
    "            trainerror = performance(name, train, train, g_labels, metric, k)\n",
    "            generalizationerror = score - trainerror\n",
    "            generalization_error = np.append(generalization_error, generalizationerror)\n",
    "\n",
    "    result = np.append(classifier_performance, generalization_error)\n",
    "\n",
    "    if generalization == \"Yes\":\n",
    "        for i in range(folds):\n",
    "            result = np.append(result, (result[i] - result[i + folds]))\n",
    "    return result\n",
    "    #return generalization_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b(iv)\n",
    "#return classifier performance across each fold\n",
    "#option in function CV to also return training and generalization errror\n",
    "def foldperformance(scores, folds):\n",
    "\n",
    "    classifiermean = np.mean(scores[: folds])\n",
    "    twentyfive = np.percentile(scores[: folds], 25)\n",
    "    seventyfive = np.percentile(scores[: folds], 75)\n",
    "    \n",
    "    if len(scores) > folds:\n",
    "        generalizationmean = np.mean(scores[folds:2*folds])\n",
    "        trainingmean = np.mean(scores[2*folds:])\n",
    "        print('mean generalization error:', generalizationmean)\n",
    "        print('mean training error:', trainingmean)\n",
    "    \n",
    "    \n",
    "    print('mean classifier performance:', classifiermean)\n",
    "    print('25th percentile of classifier:', twentyfive)\n",
    "    print('75th percentile of classifier:', seventyfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethkitahata/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.90909091 0.90909091 0.90909091 0.90909091\n",
      " 0.90909091 0.90909091 0.90909091 0.90909091 0.90909091 0.90909091]\n",
      "mean generalization error: 0.09090909090909094\n",
      "mean training error: 0.909090909090909\n",
      "mean classifier performance: 1.0\n",
      "25th percentile of classifier: 1.0\n",
      "75th percentile of classifier: 1.0\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-393-c3d4eac8959e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoldperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-384-6dd394cb7685>\u001b[0m in \u001b[0;36mCV\u001b[0;34m(data, folds, k, name, metric, generalization)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mclassifier_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#run CV for 10 folds and create graph of performance across folds\n",
    "for i in range(1, 15, 2):\n",
    "    scores = CV(training_s1, 10, i, 'KNN', 'accuracy', 'Yes')\n",
    "    print(scores)\n",
    "    performance = foldperformance(scores, 10)\n",
    "    print(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
